{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tflearn","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:38:36.376621Z","iopub.execute_input":"2022-03-01T17:38:36.376944Z","iopub.status.idle":"2022-03-01T17:38:47.070079Z","shell.execute_reply.started":"2022-03-01T17:38:36.376855Z","shell.execute_reply":"2022-03-01T17:38:47.069308Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tflearn\n  Downloading tflearn-0.5.0.tar.gz (107 kB)\n     |████████████████████████████████| 107 kB 935 kB/s            \n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tflearn) (1.20.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tflearn) (1.16.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from tflearn) (8.2.0)\nBuilding wheels for collected packages: tflearn\n  Building wheel for tflearn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=9d823e4f77984b1697d3236ff67c7b12ed5f7e9371fee3d76bcabe26aa842092\n  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\nSuccessfully built tflearn\nInstalling collected packages: tflearn\nSuccessfully installed tflearn-0.5.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import  Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom keras.datasets import cifar10\n\nimport tflearn.datasets.oxflower17 as oxflower17\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-01T17:38:47.072157Z","iopub.execute_input":"2022-03-01T17:38:47.072423Z","iopub.status.idle":"2022-03-01T17:38:52.128393Z","shell.execute_reply.started":"2022-03-01T17:38:47.072390Z","shell.execute_reply":"2022-03-01T17:38:52.127676Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X, Y = oxflower17.load_data(one_hot=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:38:52.129619Z","iopub.execute_input":"2022-03-01T17:38:52.130126Z","iopub.status.idle":"2022-03-01T17:39:13.215634Z","shell.execute_reply.started":"2022-03-01T17:38:52.130089Z","shell.execute_reply":"2022-03-01T17:39:13.214917Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading Oxford 17 category Flower Dataset, Please wait...\n","output_type":"stream"},{"name":"stderr","text":"100.0% 60276736 / 60270631\n","output_type":"stream"},{"name":"stdout","text":"Succesfully downloaded 17flowers.tgz 60270631 bytes.\nFile Extracted\nStarting to parse images...\nParsing Done!\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(1584, activation='tanh'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1024, activation='tanh'))\nmodel.add(Dropout(0.1))\n\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(17, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:39:13.217500Z","iopub.execute_input":"2022-03-01T17:39:13.217836Z","iopub.status.idle":"2022-03-01T17:39:13.566608Z","shell.execute_reply.started":"2022-03-01T17:39:13.217798Z","shell.execute_reply":"2022-03-01T17:39:13.565926Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Compiling the model\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:39:13.567650Z","iopub.execute_input":"2022-03-01T17:39:13.567881Z","iopub.status.idle":"2022-03-01T17:39:13.632678Z","shell.execute_reply.started":"2022-03-01T17:39:13.567849Z","shell.execute_reply":"2022-03-01T17:39:13.632048Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X, Y, batch_size=28, epochs=100, verbose=1, validation_split=0.3, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:39:13.633763Z","iopub.execute_input":"2022-03-01T17:39:13.634028Z","iopub.status.idle":"2022-03-01T17:40:52.655925Z","shell.execute_reply.started":"2022-03-01T17:39:13.633978Z","shell.execute_reply":"2022-03-01T17:40:52.655201Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Train on 951 samples, validate on 409 samples\n","output_type":"stream"},{"name":"stderr","text":"2022-03-01 17:39:14.117664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-01 17:39:14.219485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-01 17:39:14.220167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-01 17:39:14.221340: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-03-01 17:39:14.222328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-01 17:39:14.223363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-01 17:39:14.224262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-01 17:39:15.912494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-01 17:39:15.913546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-01 17:39:15.914431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-01 17:39:15.915203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2022-03-01 17:39:17.705513: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"951/951 [==============================] - ETA: 0s - loss: 3.0719 - acc: 0.2587","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  warnings.warn('`Model.state_updates` will be removed in a future version. '\n","output_type":"stream"},{"name":"stdout","text":"951/951 [==============================] - 8s 9ms/sample - loss: 3.0719 - acc: 0.2587 - val_loss: 4.5035 - val_acc: 0.0758\nEpoch 2/100\n951/951 [==============================] - 1s 967us/sample - loss: 1.8880 - acc: 0.3912 - val_loss: 3.5155 - val_acc: 0.1540\nEpoch 3/100\n951/951 [==============================] - 1s 1000us/sample - loss: 1.7786 - acc: 0.4395 - val_loss: 2.2953 - val_acc: 0.3178\nEpoch 4/100\n951/951 [==============================] - 1s 1000us/sample - loss: 1.6994 - acc: 0.4479 - val_loss: 2.3893 - val_acc: 0.3350\nEpoch 5/100\n951/951 [==============================] - 1s 1ms/sample - loss: 1.6480 - acc: 0.4543 - val_loss: 1.8364 - val_acc: 0.3961\nEpoch 6/100\n951/951 [==============================] - 1s 930us/sample - loss: 1.4671 - acc: 0.5237 - val_loss: 5.0360 - val_acc: 0.2127\nEpoch 7/100\n951/951 [==============================] - 1s 924us/sample - loss: 1.4657 - acc: 0.5100 - val_loss: 2.3407 - val_acc: 0.3667\nEpoch 8/100\n951/951 [==============================] - 1s 912us/sample - loss: 1.4401 - acc: 0.5426 - val_loss: 2.5507 - val_acc: 0.3178\nEpoch 9/100\n951/951 [==============================] - 1s 901us/sample - loss: 1.3112 - acc: 0.5699 - val_loss: 2.0808 - val_acc: 0.4181\nEpoch 10/100\n951/951 [==============================] - 1s 922us/sample - loss: 1.1509 - acc: 0.6225 - val_loss: 2.5022 - val_acc: 0.4205\nEpoch 11/100\n951/951 [==============================] - 1s 905us/sample - loss: 1.1188 - acc: 0.6225 - val_loss: 3.2836 - val_acc: 0.3007\nEpoch 12/100\n951/951 [==============================] - 1s 917us/sample - loss: 1.1250 - acc: 0.6120 - val_loss: 2.6529 - val_acc: 0.2347\nEpoch 13/100\n951/951 [==============================] - 1s 922us/sample - loss: 1.3543 - acc: 0.5478 - val_loss: 2.4196 - val_acc: 0.3814\nEpoch 14/100\n951/951 [==============================] - 1s 916us/sample - loss: 1.1404 - acc: 0.6109 - val_loss: 1.8959 - val_acc: 0.4719\nEpoch 15/100\n951/951 [==============================] - 1s 920us/sample - loss: 1.0270 - acc: 0.6372 - val_loss: 2.2958 - val_acc: 0.3423\nEpoch 16/100\n951/951 [==============================] - 1s 928us/sample - loss: 0.8962 - acc: 0.6961 - val_loss: 2.6771 - val_acc: 0.4010\nEpoch 17/100\n951/951 [==============================] - 1s 966us/sample - loss: 0.8622 - acc: 0.7066 - val_loss: 2.8837 - val_acc: 0.3643\nEpoch 18/100\n951/951 [==============================] - 1s 957us/sample - loss: 0.8189 - acc: 0.7066 - val_loss: 3.1489 - val_acc: 0.3325\nEpoch 19/100\n951/951 [==============================] - 1s 897us/sample - loss: 0.7336 - acc: 0.7382 - val_loss: 2.8656 - val_acc: 0.3545\nEpoch 20/100\n951/951 [==============================] - 1s 916us/sample - loss: 0.6715 - acc: 0.7687 - val_loss: 2.5140 - val_acc: 0.4108\nEpoch 21/100\n951/951 [==============================] - 1s 915us/sample - loss: 0.6339 - acc: 0.7750 - val_loss: 3.2529 - val_acc: 0.3741\nEpoch 22/100\n951/951 [==============================] - 1s 920us/sample - loss: 0.6151 - acc: 0.7960 - val_loss: 2.1789 - val_acc: 0.4768\nEpoch 23/100\n951/951 [==============================] - 1s 920us/sample - loss: 0.5553 - acc: 0.8212 - val_loss: 1.9986 - val_acc: 0.5061\nEpoch 24/100\n951/951 [==============================] - 1s 899us/sample - loss: 0.5945 - acc: 0.7981 - val_loss: 2.9170 - val_acc: 0.3912\nEpoch 25/100\n951/951 [==============================] - 1s 917us/sample - loss: 0.5194 - acc: 0.8202 - val_loss: 2.8456 - val_acc: 0.4205\nEpoch 26/100\n951/951 [==============================] - 1s 899us/sample - loss: 0.3962 - acc: 0.8696 - val_loss: 2.8081 - val_acc: 0.4205\nEpoch 27/100\n951/951 [==============================] - 1s 912us/sample - loss: 0.4316 - acc: 0.8538 - val_loss: 2.1700 - val_acc: 0.5379\nEpoch 28/100\n951/951 [==============================] - 1s 911us/sample - loss: 0.3812 - acc: 0.8812 - val_loss: 2.9319 - val_acc: 0.4670\nEpoch 29/100\n951/951 [==============================] - 1s 907us/sample - loss: 0.3133 - acc: 0.8885 - val_loss: 3.8340 - val_acc: 0.3961\nEpoch 30/100\n951/951 [==============================] - 1s 1ms/sample - loss: 0.2606 - acc: 0.8991 - val_loss: 2.8637 - val_acc: 0.4988\nEpoch 31/100\n951/951 [==============================] - 1s 944us/sample - loss: 0.3193 - acc: 0.8906 - val_loss: 3.0850 - val_acc: 0.4425\nEpoch 32/100\n951/951 [==============================] - 1s 905us/sample - loss: 0.2999 - acc: 0.9012 - val_loss: 2.6474 - val_acc: 0.5208\nEpoch 33/100\n951/951 [==============================] - 1s 919us/sample - loss: 0.2206 - acc: 0.9232 - val_loss: 3.6777 - val_acc: 0.4010\nEpoch 34/100\n951/951 [==============================] - 1s 915us/sample - loss: 0.1919 - acc: 0.9380 - val_loss: 4.7750 - val_acc: 0.3790\nEpoch 35/100\n951/951 [==============================] - 1s 904us/sample - loss: 0.2508 - acc: 0.9106 - val_loss: 2.5200 - val_acc: 0.5257\nEpoch 36/100\n951/951 [==============================] - 1s 919us/sample - loss: 0.7834 - acc: 0.7592 - val_loss: 3.7421 - val_acc: 0.3667\nEpoch 37/100\n951/951 [==============================] - 1s 906us/sample - loss: 0.6341 - acc: 0.7928 - val_loss: 3.2544 - val_acc: 0.4205\nEpoch 38/100\n951/951 [==============================] - 1s 900us/sample - loss: 0.4371 - acc: 0.8612 - val_loss: 3.3024 - val_acc: 0.4377\nEpoch 39/100\n951/951 [==============================] - 1s 915us/sample - loss: 0.2390 - acc: 0.9085 - val_loss: 2.1230 - val_acc: 0.5966\nEpoch 40/100\n951/951 [==============================] - 1s 1ms/sample - loss: 0.2204 - acc: 0.9327 - val_loss: 2.7379 - val_acc: 0.5281\nEpoch 41/100\n951/951 [==============================] - 1s 951us/sample - loss: 0.1627 - acc: 0.9506 - val_loss: 2.8184 - val_acc: 0.5648\nEpoch 42/100\n951/951 [==============================] - 1s 1ms/sample - loss: 0.1142 - acc: 0.9632 - val_loss: 2.1380 - val_acc: 0.6186\nEpoch 43/100\n951/951 [==============================] - 1s 936us/sample - loss: 0.0964 - acc: 0.9664 - val_loss: 2.2282 - val_acc: 0.5721\nEpoch 44/100\n951/951 [==============================] - 1s 904us/sample - loss: 0.0816 - acc: 0.9727 - val_loss: 2.1163 - val_acc: 0.5917\nEpoch 45/100\n951/951 [==============================] - 1s 926us/sample - loss: 0.1230 - acc: 0.9590 - val_loss: 3.0690 - val_acc: 0.5501\nEpoch 46/100\n951/951 [==============================] - 1s 909us/sample - loss: 0.1003 - acc: 0.9653 - val_loss: 2.5182 - val_acc: 0.5697\nEpoch 47/100\n951/951 [==============================] - 1s 903us/sample - loss: 0.1131 - acc: 0.9590 - val_loss: 2.8428 - val_acc: 0.5550\nEpoch 48/100\n951/951 [==============================] - 1s 913us/sample - loss: 0.1290 - acc: 0.9600 - val_loss: 3.6471 - val_acc: 0.4719\nEpoch 49/100\n951/951 [==============================] - 1s 898us/sample - loss: 0.1024 - acc: 0.9611 - val_loss: 2.4471 - val_acc: 0.6088\nEpoch 50/100\n951/951 [==============================] - 1s 902us/sample - loss: 0.1204 - acc: 0.9600 - val_loss: 2.3689 - val_acc: 0.6039\nEpoch 51/100\n951/951 [==============================] - 1s 907us/sample - loss: 0.0803 - acc: 0.9727 - val_loss: 2.3720 - val_acc: 0.6088\nEpoch 52/100\n951/951 [==============================] - 1s 916us/sample - loss: 0.1063 - acc: 0.9642 - val_loss: 2.5327 - val_acc: 0.5990\nEpoch 53/100\n951/951 [==============================] - 1s 954us/sample - loss: 0.0998 - acc: 0.9590 - val_loss: 2.1812 - val_acc: 0.6039\nEpoch 54/100\n951/951 [==============================] - 1s 907us/sample - loss: 0.1590 - acc: 0.9558 - val_loss: 2.6180 - val_acc: 0.5550\nEpoch 55/100\n951/951 [==============================] - 1s 1ms/sample - loss: 0.1512 - acc: 0.9548 - val_loss: 2.6075 - val_acc: 0.6015\nEpoch 56/100\n951/951 [==============================] - 1s 920us/sample - loss: 0.0633 - acc: 0.9842 - val_loss: 2.0401 - val_acc: 0.6186\nEpoch 57/100\n951/951 [==============================] - 1s 917us/sample - loss: 0.1169 - acc: 0.9590 - val_loss: 2.4891 - val_acc: 0.5941\nEpoch 58/100\n951/951 [==============================] - 1s 902us/sample - loss: 0.1546 - acc: 0.9443 - val_loss: 2.8016 - val_acc: 0.5966\nEpoch 59/100\n951/951 [==============================] - 1s 908us/sample - loss: 0.0820 - acc: 0.9706 - val_loss: 3.1683 - val_acc: 0.5575\nEpoch 60/100\n951/951 [==============================] - 1s 914us/sample - loss: 0.0851 - acc: 0.9716 - val_loss: 2.2949 - val_acc: 0.6161\nEpoch 61/100\n951/951 [==============================] - 1s 907us/sample - loss: 0.0731 - acc: 0.9748 - val_loss: 3.3811 - val_acc: 0.4108\nEpoch 62/100\n951/951 [==============================] - 1s 923us/sample - loss: 0.0665 - acc: 0.9748 - val_loss: 3.3454 - val_acc: 0.4328\nEpoch 63/100\n951/951 [==============================] - 1s 918us/sample - loss: 0.1326 - acc: 0.9590 - val_loss: 2.5515 - val_acc: 0.5966\nEpoch 64/100\n951/951 [==============================] - 1s 921us/sample - loss: 0.0901 - acc: 0.9674 - val_loss: 2.6517 - val_acc: 0.6064\nEpoch 65/100\n951/951 [==============================] - 1s 941us/sample - loss: 0.0650 - acc: 0.9769 - val_loss: 2.1562 - val_acc: 0.6455\nEpoch 66/100\n951/951 [==============================] - 1s 927us/sample - loss: 0.0616 - acc: 0.9727 - val_loss: 2.2013 - val_acc: 0.6577\nEpoch 67/100\n951/951 [==============================] - 1s 1ms/sample - loss: 0.0600 - acc: 0.9811 - val_loss: 2.1616 - val_acc: 0.6357\nEpoch 68/100\n951/951 [==============================] - 1s 936us/sample - loss: 0.0415 - acc: 0.9884 - val_loss: 2.0372 - val_acc: 0.6773\nEpoch 69/100\n951/951 [==============================] - 1s 915us/sample - loss: 0.0687 - acc: 0.9737 - val_loss: 2.4514 - val_acc: 0.6284\nEpoch 70/100\n951/951 [==============================] - 1s 908us/sample - loss: 0.0767 - acc: 0.9769 - val_loss: 2.5363 - val_acc: 0.6235\nEpoch 71/100\n951/951 [==============================] - 1s 920us/sample - loss: 0.0593 - acc: 0.9790 - val_loss: 2.5209 - val_acc: 0.6333\nEpoch 72/100\n951/951 [==============================] - 1s 917us/sample - loss: 0.0745 - acc: 0.9790 - val_loss: 2.3346 - val_acc: 0.6284\nEpoch 73/100\n951/951 [==============================] - 1s 931us/sample - loss: 0.0495 - acc: 0.9853 - val_loss: 4.3517 - val_acc: 0.3545\nEpoch 74/100\n951/951 [==============================] - 1s 913us/sample - loss: 0.0466 - acc: 0.9853 - val_loss: 3.1094 - val_acc: 0.5770\nEpoch 75/100\n951/951 [==============================] - 1s 946us/sample - loss: 0.0821 - acc: 0.9716 - val_loss: 2.3351 - val_acc: 0.6308\nEpoch 76/100\n951/951 [==============================] - 1s 1ms/sample - loss: 0.1670 - acc: 0.9590 - val_loss: 5.1540 - val_acc: 0.2641\nEpoch 77/100\n951/951 [==============================] - 1s 906us/sample - loss: 0.1364 - acc: 0.9579 - val_loss: 4.9984 - val_acc: 0.2543\nEpoch 78/100\n951/951 [==============================] - 1s 897us/sample - loss: 0.1495 - acc: 0.9548 - val_loss: 2.5730 - val_acc: 0.5428\nEpoch 79/100\n951/951 [==============================] - 1s 977us/sample - loss: 0.1235 - acc: 0.9569 - val_loss: 2.9306 - val_acc: 0.5159\nEpoch 80/100\n951/951 [==============================] - 1s 961us/sample - loss: 0.1232 - acc: 0.9579 - val_loss: 3.8988 - val_acc: 0.4328\nEpoch 81/100\n951/951 [==============================] - 1s 919us/sample - loss: 0.0978 - acc: 0.9706 - val_loss: 5.5673 - val_acc: 0.3203\nEpoch 82/100\n951/951 [==============================] - 1s 900us/sample - loss: 0.0751 - acc: 0.9790 - val_loss: 2.8883 - val_acc: 0.5746\nEpoch 83/100\n951/951 [==============================] - 1s 925us/sample - loss: 0.0657 - acc: 0.9790 - val_loss: 3.5679 - val_acc: 0.5746\nEpoch 84/100\n951/951 [==============================] - 1s 929us/sample - loss: 0.0615 - acc: 0.9758 - val_loss: 2.6986 - val_acc: 0.6161\nEpoch 85/100\n951/951 [==============================] - 1s 902us/sample - loss: 0.1437 - acc: 0.9579 - val_loss: 2.7183 - val_acc: 0.5819\nEpoch 86/100\n951/951 [==============================] - 1s 900us/sample - loss: 0.1837 - acc: 0.9516 - val_loss: 3.7357 - val_acc: 0.4352\nEpoch 87/100\n951/951 [==============================] - 1s 930us/sample - loss: 0.0836 - acc: 0.9716 - val_loss: 3.4670 - val_acc: 0.5159\nEpoch 88/100\n951/951 [==============================] - 1s 895us/sample - loss: 0.0584 - acc: 0.9821 - val_loss: 2.5036 - val_acc: 0.6381\nEpoch 89/100\n951/951 [==============================] - 1s 916us/sample - loss: 0.0692 - acc: 0.9800 - val_loss: 2.7379 - val_acc: 0.5941\nEpoch 90/100\n951/951 [==============================] - 1s 897us/sample - loss: 0.1556 - acc: 0.9506 - val_loss: 7.6417 - val_acc: 0.1418\nEpoch 91/100\n951/951 [==============================] - 1s 910us/sample - loss: 0.3363 - acc: 0.9012 - val_loss: 4.0741 - val_acc: 0.4523\nEpoch 92/100\n951/951 [==============================] - 1s 995us/sample - loss: 0.4415 - acc: 0.8864 - val_loss: 6.7935 - val_acc: 0.1809\nEpoch 93/100\n951/951 [==============================] - 1s 921us/sample - loss: 0.7186 - acc: 0.8034 - val_loss: 3.4543 - val_acc: 0.4181\nEpoch 94/100\n951/951 [==============================] - 1s 928us/sample - loss: 0.2288 - acc: 0.9295 - val_loss: 2.5447 - val_acc: 0.5403\nEpoch 95/100\n951/951 [==============================] - 1s 903us/sample - loss: 0.1388 - acc: 0.9464 - val_loss: 2.7137 - val_acc: 0.5697\nEpoch 96/100\n951/951 [==============================] - 1s 895us/sample - loss: 0.0702 - acc: 0.9727 - val_loss: 3.3007 - val_acc: 0.5281\nEpoch 97/100\n951/951 [==============================] - 1s 905us/sample - loss: 0.0583 - acc: 0.9779 - val_loss: 2.1792 - val_acc: 0.6479\nEpoch 98/100\n951/951 [==============================] - 1s 904us/sample - loss: 0.0350 - acc: 0.9916 - val_loss: 2.1408 - val_acc: 0.6553\nEpoch 99/100\n951/951 [==============================] - 1s 916us/sample - loss: 0.0216 - acc: 0.9937 - val_loss: 2.1618 - val_acc: 0.6822\nEpoch 100/100\n951/951 [==============================] - 1s 897us/sample - loss: 0.0282 - acc: 0.9874 - val_loss: 2.0898 - val_acc: 0.6797\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T17:40:52.657478Z","iopub.execute_input":"2022-03-01T17:40:52.657732Z","iopub.status.idle":"2022-03-01T17:40:52.672510Z","shell.execute_reply.started":"2022-03-01T17:40:52.657697Z","shell.execute_reply":"2022-03-01T17:40:52.671641Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 54, 54, 96)        34944     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 26, 26, 96)        384       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 22, 22, 256)       614656    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 10, 10, 256)       0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 10, 10, 256)       1024      \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 8, 8, 256)         590080    \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 1, 1, 384)         0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 1, 1, 384)         1536      \n_________________________________________________________________\nflatten (Flatten)            (None, 384)               0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 384)               1536      \n_________________________________________________________________\ndense (Dense)                (None, 1584)              609840    \n_________________________________________________________________\ndropout (Dropout)            (None, 1584)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1024)              1623040   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 1024)              4096      \n_________________________________________________________________\ndense_2 (Dense)              (None, 17)                17425     \n=================================================================\nTotal params: 5,711,169\nTrainable params: 5,706,881\nNon-trainable params: 4,288\n_________________________________________________________________\n","output_type":"stream"}]}]}